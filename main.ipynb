{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liberaries init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "import torch\n",
    "from torch.utils.data import DataLoader ,  Dataset\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR ,    MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global use\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preproccessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_files_from_dir(dir_path: Path) -> dict[str ,  List[Path] ]:\n",
    "    \"\"\"\n",
    "    from participants directory returns files path orginized in relation to task and run \n",
    "    exemple \n",
    "    dic = {\n",
    "    \"contrastchangeDetection_run-1\" : [path1,path2,path3],\n",
    "    ...   \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dir_path , \"eeg\")\n",
    "    participant_files = {}\n",
    "    for file in os.listdir(dir_path):\n",
    "        elements = file.split(\"_\")\n",
    "        if len(elements ) == 3 :\n",
    "            elements.insert(2 , \"run-1\")\n",
    "        elements[1] += \"_\"+ elements[2]\n",
    "        del elements[2]\n",
    "        if elements[1] not in participant_files:\n",
    "            participant_files[elements[1]] = [Path(os.path.join(dir_path , file))]\n",
    "        else:\n",
    "            participant_files[elements[1]].append(Path(os.path.join(dir_path , file)))\n",
    "    # aka each task has the events , channels , eeg json and eeg raw\n",
    "    for key in participant_files  :\n",
    "        assert len(participant_files[key]) == 4 \n",
    "    return participant_files\n",
    "def prepare_ccd_events(events_fp : Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    from events file returns a dataframe with trial start , trial end , stimulas start , action onset , RT AND SUCCESS\n",
    "\n",
    "    \"\"\"\n",
    "    assert os.path.splitext(events_fp)[1] == \".tsv\"\n",
    "    events = pd.read_csv(events_fp , sep = \"\\t\")\n",
    "    events[\"onset\"] = pd.to_numeric(events[\"onset\"],errors=\"raise\")   \n",
    "    events = events.reset_index(drop=True)\n",
    "    events = events.sort_values(by=\"onset\" , ascending=True)\n",
    "    trials = events[ events[\"value\"] == \"contrastTrial_start\"].copy()\n",
    "    trials[\"trial_start\"] = trials[\"onset\"]\n",
    "\n",
    "    trials[\"trial_end\"] = trials[\"onset\"].shift(-1) \n",
    "    stimulas = events [ events[\"value\"].isin([\"right_target\" ,\"left_target\"])].copy()\n",
    "    action = events [ events[\"value\"].isin([\"right_buttonPress\" ,\"left_buttonPress\"])].copy()\n",
    "    results = []\n",
    "    for i in range(0 ,len(trials)-1 ):\n",
    "        #get the stimulas onset in the trial i duration\n",
    "        stimulas_row = stimulas[ (stimulas[\"onset\"] >= trials[\"trial_start\"].iloc[i]) & (stimulas[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        if stimulas_row.empty:\n",
    "            continue\n",
    "        stimulas_start = float(stimulas_row[\"onset\"].iloc[0])\n",
    "\n",
    "        action_rows = action[ (action[\"onset\"] >= stimulas_start) & (action[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        # if theres no action , theres no rt , theres no success\n",
    "        if action_rows.empty:\n",
    "            \n",
    "            continue\n",
    "        action_row = action_rows.iloc[0]\n",
    "        action_onset = float(action_row[\"onset\"])\n",
    "        rt = action_onset - stimulas_start\n",
    "        success = 1 if action_row[\"feedback\"] == \"smiley_face\" else 0\n",
    "        result ={\n",
    "        \"trial_start\" : float(trials[\"trial_start\"].iloc[i]) ,\n",
    "        \"trial_end\" :float(trials[\"trial_end\"].iloc[i]) ,\n",
    "        \"stimulas_start\" : stimulas_start,\n",
    "        \"action_onset\" :action_onset  ,\n",
    "        \"rt\" : rt ,\n",
    "        \"success\" : success\n",
    "        }\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_participants_ccd_data(data_dir: Path) -> Dict[str , Dict[str , Tuple[DataFrame , Path]]]:\n",
    "\n",
    "    #dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \n",
    "    results = {}\n",
    "    for release in os.listdir(data_dir):\n",
    "        release_dir_path = os.path.join(data_dir , release)\n",
    "        #go throught the participants directory\n",
    "        for file in os.listdir(release_dir_path):\n",
    "            \n",
    "            if not  file.split(\"-\")[0] == \"sub\" :\n",
    "                continue\n",
    "\n",
    "            participant_id = file\n",
    "            participant_dir_path = os.path.join(release_dir_path , file)\n",
    "\n",
    "            results[participant_dir_path] = {}\n",
    "            participant_files = load_participant_files_from_dir(participant_dir_path)\n",
    "            filtered_participant_files = {}\n",
    "            # filter for ccd and sus data\n",
    "            for key in participant_files:\n",
    "                if key.split(\"_\")[0].lower() == \"task-contrastchangedetection\" :\n",
    "                    filtered_participant_files[key] = participant_files[key]\n",
    "            \n",
    "            for task , files in filtered_participant_files.items():\n",
    "                events_path = [path for path in files if \"events\" in str(path)]  \n",
    "                assert len(events_path) == 1\n",
    "                events_path = events_path[0]\n",
    "                eeg_path = [path for path in files if \".set\" in str(path)]\n",
    "\n",
    "                assert len(eeg_path) == 1\n",
    "                df = prepare_ccd_events(events_path)\n",
    "                results[participant_dir_path][task] = (df , eeg_path[0])\n",
    "    return results\n",
    "\n",
    "def participants_ccd_data_to_list(data : dict) -> List[Tuple[DataFrame , Path]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        for task in data[participant]:\n",
    "            results.append(data[participant][task])\n",
    "    return results\n",
    "            \n",
    "def participants_ccd_list_to_trial_rt_pair(data : List[Tuple[DataFrame , Path]]) -> List[Tuple[Path ,Tuple[float,float] , float]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        df , eeg_path = participant\n",
    "        for i in range(0 , len(df)):\n",
    "            results.append((eeg_path , (df[\"stimulas_start\"].iloc[i]+0.5 , df[\"stimulas_start\"].iloc[i]+2.5 ) , df[\"rt\"].iloc[i]))\n",
    "    return results\n",
    "\n",
    "def train_val_test_split_by_subject(data : List[Tuple[Path ,Tuple[float,float] , float]] , test_size : float = 0.1 , val_size : float = 0.1) -> Tuple[List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]]]:\n",
    "    subjects = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject not in subjects:\n",
    "            subjects.append(subject)\n",
    "    train_subjects , test_subjects = train_test_split(subjects , test_size=test_size +val_size)\n",
    "    test_subjects , val_subjects = train_test_split(test_subjects , test_size=val_size/(test_size +val_size))\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    val_data = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject in train_subjects:\n",
    "            train_data.append(element)\n",
    "        elif subject in test_subjects:\n",
    "            test_data.append(element)\n",
    "        elif subject in val_subjects:\n",
    "            val_data.append(element)\n",
    "    return train_data , val_data , test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500\n"
     ]
    }
   ],
   "source": [
    "data_path= r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\data\"\n",
    "data = prepare_participants_ccd_data(data_path)\n",
    "\n",
    "data = participants_ccd_data_to_list(data)\n",
    "data = participants_ccd_list_to_trial_rt_pair(data)\n",
    "train , val , test = train_val_test_split_by_subject(data)\n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the raw eeg windows data and setting them up for fast import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_to_fast_loading_shards(data : List[Tuple[Path ,Tuple[float,float] , float]] , split = \"train\" , shard_size : int = 1000):\n",
    "    shards_path = \"shards_dir\"\n",
    "    split_path = os.path.join(shards_path , split)\n",
    "\n",
    "    if not os.path.exists(shards_path):\n",
    "        os.makedirs(shards_path)\n",
    "\n",
    "    if not os.path.exists(split_path):\n",
    "        os.makedirs(split_path)\n",
    "    else:\n",
    "        return split_path\n",
    "\n",
    "\n",
    "    shard_index=0\n",
    "    window_shard_path = os.path.join(split_path , f\"window_shard_{shard_index}.npy\")\n",
    "    rt_shard_path = os.path.join(split_path , f\"rt_shard_{shard_index}.npy\")\n",
    "    windows =[]\n",
    "    rts =[]\n",
    "    for index , element in tqdm(enumerate(data)):\n",
    "        if index!=0 and index % shard_size == 0:\n",
    "            window_array = np.array(windows)\n",
    "            rt_array = np.array(rts)\n",
    "            X = np.lib.format.open_memmap(window_shard_path , dtype='float32' , mode='w+' , shape=(window_array.shape[0] , window_array.shape[1] , window_array.shape[2]))\n",
    "            X[:] = window_array\n",
    "            del X\n",
    "            Y = np.lib.format.open_memmap(rt_shard_path , dtype='float32' , mode='w+' , shape=(rt_array.shape[0] ,))\n",
    "            Y[:] = rt_array\n",
    "            del Y\n",
    "            shard_index+=1\n",
    "            window_shard_path = os.path.join(split_path , f\"window_shard_{shard_index}.npy\")\n",
    "            rt_shard_path = os.path.join(split_path , f\"rt_shard_{shard_index}.npy\")\n",
    "            windows =[]\n",
    "            rts =[]\n",
    "        eeg_path , (start , end) , rt = element\n",
    "        eeg = mne.io.read_raw_eeglab(eeg_path , preload=True)\n",
    "        eeg = eeg.crop(start , end+0.2)\n",
    "        raw = eeg.get_data()[: ,:200]\n",
    "        windows.append(raw)\n",
    "        rts.append(rt)\n",
    "    window_array = np.array(windows)\n",
    "    rt_array = np.array(rts)\n",
    "    if len(window_array) > 0:\n",
    "        X = np.lib.format.open_memmap(window_shard_path , dtype='float32' , mode='w+' , shape=(window_array.shape[0] , window_array.shape[1] , window_array.shape[2]))\n",
    "        X[:] = window_array\n",
    "        del X\n",
    "        Y = np.lib.format.open_memmap(rt_shard_path , dtype='float32' , mode='w+' , shape=(rt_array.shape[0] ,))\n",
    "        Y[:] = rt_array\n",
    "        del Y\n",
    "    return split_path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8478it [15:57,  8.85it/s]\n",
      "1108it [01:52,  9.86it/s]\n",
      "914it [01:31, 10.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shards_dir\\\\val'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_size = 1000\n",
    "pairs_to_fast_loading_shards(train , \"train\" ,shard_size)\n",
    "pairs_to_fast_loading_shards(test , \"test\",shard_size)\n",
    "pairs_to_fast_loading_shards(val , \"val\",shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self , shards_path , shard_size  =1000):\n",
    "        self.shards_path = shards_path\n",
    "        self.numbers_of_shards = int( len(os.listdir(self.shards_path)) / 2)\n",
    "        self.shard_size = shard_size\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for shard_path in os.listdir(self.shards_path):\n",
    "            if \"window\" in shard_path:\n",
    "                window_shard_path = os.path.join(self.shards_path , shard_path)\n",
    "                shard = np.lib.format.open_memmap(window_shard_path , mode=\"r\")\n",
    "                size = shard.shape[0]\n",
    "                length += size\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        shard_pos = index // self.shard_size \n",
    "        window_shard_path = os.path.join(self.shards_path , f\"window_shard_{shard_pos}.npy\")\n",
    "        X = np.lib.format.open_memmap(window_shard_path , mode=\"r\")\n",
    "        rt_shard_path = os.path.join(self.shards_path , f\"rt_shard_{shard_pos}.npy\")\n",
    "        Y = np.lib.format.open_memmap(rt_shard_path , mode=\"r\")\n",
    "        raw = X[index % self.shard_size]\n",
    "        rt = Y[index % self.shard_size]\n",
    "        return raw , rt\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 200)\n",
      "1.768\n"
     ]
    }
   ],
   "source": [
    "train_pairs_shards_path = pairs_to_fast_loading_shards(train , \"train\" , shard_size)\n",
    "test_pairs_shards_path = pairs_to_fast_loading_shards(test , \"test\" ,  shard_size)\n",
    "val_pairs_shards_path =pairs_to_fast_loading_shards(val , \"val\" , shard_size)\n",
    "train_data = EEGDataset(train_pairs_shards_path ,  shard_size)\n",
    "test_data = EEGDataset(test_pairs_shards_path , shard_size)\n",
    "val_data = EEGDataset(val_pairs_shards_path ,shard_size)\n",
    "eeg , rt=train_data[0]\n",
    "print(eeg.shape)\n",
    "print(rt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse_over_data(model, dataloader, device):\n",
    "    model.eval()\n",
    "    se_sum = 0.0     # sum of squared errors\n",
    "    sum_y = 0.0      # sum of y\n",
    "    sum_y2 = 0.0     # sum of y^2\n",
    "    n = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x).view_as(y)\n",
    "            diff = y_pred - y\n",
    "\n",
    "            se_sum += diff.pow(2).sum().item()\n",
    "            sum_y  += y.sum().item()\n",
    "            sum_y2 += y.pow(2).sum().item()\n",
    "            n += y.numel()\n",
    "\n",
    "    rmse = (se_sum / n) ** 0.5\n",
    "    var  = (sum_y2 / n) - (sum_y / n) ** 2\n",
    "    std  = var ** 0.5\n",
    "    return rmse / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importance_extraction(nn.Module):\n",
    "    def __init__(self , nb_channels = 129 , nb_times= 200 ):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear( nb_times , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 1)   \n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self , x):\n",
    "        x = self.classifier(x)\n",
    "        return self.softmax(x)  \n",
    "      \n",
    "    \n",
    "class Section_attention(nn.Module):\n",
    "    def __init__(self , nb_channels=129 , nb_times=10):\n",
    "        super().__init__()\n",
    "        self.nb_channels = nb_channels\n",
    "        self.nb_times = nb_times\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self , Q , K , V):\n",
    "        attn = self.softmax((Q @ K.transpose(-1 , -2)) / (self.nb_times ** 0.5))\n",
    "        res = attn @ V\n",
    "        return res\n",
    "\n",
    "\n",
    "class Multi_section_attention(nn.Module):\n",
    "    def __init__(self , nb_channels=129 , nb_times=200 , nb_output=1 , section_size=10):\n",
    "        super().__init__()\n",
    "        self.importance  = Importance_extraction(nb_channels , nb_times)\n",
    "        self.section_attention = Section_attention(nb_channels , section_size)\n",
    "\n",
    "        self.section_size = section_size\n",
    "        self.nb_of_sections = nb_times // section_size\n",
    "        self.ll = nn.Linear(nb_times , nb_times)\n",
    "        self.nb_times = nb_times\n",
    "        self.nb_channels = nb_channels\n",
    "\n",
    "        self.to_q = nn.Linear(nb_times , nb_times)\n",
    "        self.to_k = nn.Linear(nb_times , nb_times)\n",
    "        self.to_v = nn.Linear(nb_times , nb_times)\n",
    "\n",
    "    def forward(self , x):\n",
    "        imp = self.importance(x)\n",
    "        adjusted_x = x * imp\n",
    "\n",
    "        Q = self.to_q(adjusted_x)\n",
    "        K = self.to_k(adjusted_x)\n",
    "        V = self.to_v(adjusted_x)\n",
    "\n",
    "        Q = Q.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        \n",
    "        K = K.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        V =V.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        \n",
    "\n",
    "        x = self.section_attention(Q , K , V)\n",
    "        x = x.transpose(1 , 2).reshape(x.shape[0] , self.nb_channels , self.nb_times)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self ,  nb_times ):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(nb_times,) ,  requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.zeros(nb_times,) ,  requires_grad=True)\n",
    "    def forward(self , original  , attention_res):\n",
    "        add = original + attention_res\n",
    "        mean = add.mean(dim=-1,keepdim=True)\n",
    "        stand_div = add.std(dim=-1 , keepdim=True) + 1e-4 # just in case el std ta7 lel 0\n",
    "        result = (add - mean)/stand_div\n",
    "        return self.gamma * result + self.beta\n",
    "\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self , nb_channels = 129 , nb_times= 200 , nb_output = 1 , section_size = 20):\n",
    "        super().__init__()\n",
    "        self.multi_section_attention = Multi_section_attention(nb_channels , nb_times , nb_output , section_size)\n",
    "        self.add_norm = LayerNorm(nb_times)\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nb_times * nb_channels , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 1),\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        attention_res = self.multi_section_attention(x)\n",
    "        x= self.add_norm(x , attention_res)\n",
    "        x = self.classifer(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chat enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section_attention(nn.Module):\n",
    "    def __init__(self, nb_channels=129, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.nb_channels = nb_channels\n",
    "        self.section_size = section_size\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        self.scale = d_k ** 0.5\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(heads * d_k, section_size)  # bring back to section_size\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q,K,V: (b, sections, c, heads, d_k)\n",
    "        # move heads before c for matmul\n",
    "        Q = Q.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "        K = K.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "        V = V.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "\n",
    "        attn = self.softmax((Q @ K.transpose(-1, -2)) / self.scale)   # (b, sections, heads, c, c)\n",
    "        x = attn @ V                                                  # (b, sections, heads, c, d_k)\n",
    "\n",
    "        # merge heads back into feature dim per channel, then project to section_size\n",
    "        x = x.permute(0,1,3,2,4).contiguous()                         # (b, sections, c, heads, d_k)\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2], -1)            # (b, sections, c, heads*d_k)\n",
    "        x = self.out(x)                                               # (b, sections, c, section_size)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Multi_section_attention(nn.Module):\n",
    "    def __init__(self, nb_channels=129, nb_times=200, nb_output=1, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.importance  = Importance_extraction(nb_channels, nb_times)\n",
    "        self.section_size = section_size\n",
    "        self.nb_of_sections = nb_times // section_size\n",
    "        self.nb_times = nb_times\n",
    "        self.nb_channels = nb_channels\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "\n",
    "        # QKV AFTER sectioning: project last dim (section_size) → heads*d_k\n",
    "        self.to_q = nn.Linear(section_size, heads * d_k)\n",
    "        self.to_k = nn.Linear(section_size, heads * d_k)\n",
    "        self.to_v = nn.Linear(section_size, heads * d_k)\n",
    "\n",
    "        self.section_attention = Section_attention(nb_channels, section_size, heads, d_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        imp = self.importance(x)                       # (b, c, 1) softmax over channels\n",
    "        adjusted_x = x * imp                           # (b, c, t)\n",
    "\n",
    "        # split into sections\n",
    "        z = adjusted_x.reshape(adjusted_x.shape[0], adjusted_x.shape[1],\n",
    "                               self.nb_of_sections, self.section_size) \\\n",
    "                        .transpose(1, 2)               # (b, sections, c, section_size)\n",
    "\n",
    "        # per-section projections\n",
    "        Q = self.to_q(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)  # (b, sections, c, h, d_k)\n",
    "        K = self.to_k(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)\n",
    "        V = self.to_v(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)\n",
    "\n",
    "        x = self.section_attention(Q, K, V)            # (b, sections, c, section_size)\n",
    "        x = x.transpose(1, 2).reshape(x.shape[0], self.nb_channels, self.nb_times)  # (b, c, t)\n",
    "        return x\n",
    "\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self, nb_channels=129, nb_times=200, nb_output=1, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.multi_section_attention = Multi_section_attention(\n",
    "            nb_channels, nb_times, nb_output, section_size, heads, d_k\n",
    "        )\n",
    "        self.add_norm = LayerNorm(nb_times)\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            # pool over time → (b, c)\n",
    "            nn.Identity(),  # keep style\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(nb_channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.multi_section_attention(x)      # (b, c, t)\n",
    "        x = self.add_norm(x, att)                  # (b, c, t)\n",
    "\n",
    "        x = x.mean(dim=-1)                         # (b, c)   <- key change\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data , batch_size=batch_size , shuffle=True )\n",
    "test_dataloader = DataLoader(test_data , batch_size=batch_size , shuffle=True )\n",
    "val_dataloader = DataLoader(val_data , batch_size=batch_size , shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/265 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing model is working\n",
    "test_model = BaseLineModel().to(device)\n",
    "\n",
    "for  batch in tqdm(train_dataloader):\n",
    "    x , y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = test_model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blmodel = BaseLineModel().to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(blmodel.parameters() , lr=lr  )\n",
    "scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer , patience=3 )\n",
    "\n",
    "loss_f = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "train nRMSE : 4.480052098182609\n",
      "test nRMSE : 4.717848996036528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:10<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 1 , loss : 0.40520924464711605 , nRMSE : 1.0025569050593914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 1 , loss : 0.14846871665545872 , nRMSE : 1.0097055700236715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 2 , loss : 0.17553673976997158 , nRMSE : 1.0023003397262085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 30.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 2 , loss : 0.14967387872082846 , nRMSE : 1.0091809934723883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:09<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 3 , loss : 0.17405283382197595 , nRMSE : 1.0097702271613769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 3 , loss : 0.14659395068883896 , nRMSE : 1.003266740865236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:11<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 4 , loss : 0.17243017315302256 , nRMSE : 1.0010080762708315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 4 , loss : 0.14578632499490465 , nRMSE : 1.0001818349502491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 5 , loss : 0.17080556124729931 , nRMSE : 1.0143750752413943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 5 , loss : 0.15546711151088988 , nRMSE : 1.0289269138474666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 6 , loss : 0.16832041999079148 , nRMSE : 1.0251970796885526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 6 , loss : 0.1580700327243124 , nRMSE : 1.0441054706743322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 7 , loss : 0.1673442859132335 , nRMSE : 1.006906228604693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 7 , loss : 0.1506179194365229 , nRMSE : 1.0174576745936144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 8 , loss : 0.1672310360197751 , nRMSE : 1.0003092584008333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 8 , loss : 0.14689572325774602 , nRMSE : 1.0041322525051222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 0.0001\n",
      "train epoch : 9 , loss : 0.16327298660323306 , nRMSE : 1.0019474276963944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 9 , loss : 0.14592890058244978 , nRMSE : 1.0000027288596784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 10 , loss : 0.16364460593124605 , nRMSE : 1.0005962765715646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 10 , loss : 0.14559138544968198 , nRMSE : 1.0004283691311116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 11 , loss : 0.1637277679763875 , nRMSE : 1.0017963732660657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 11 , loss : 0.14632193722895215 , nRMSE : 1.0000064304217653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 12 , loss : 0.1631973660076564 , nRMSE : 1.0058162830110964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 12 , loss : 0.14644078229154858 , nRMSE : 1.0011210587203478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 13 , loss : 0.16454196268657467 , nRMSE : 1.0001906442227615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 13 , loss : 0.1467181546347482 , nRMSE : 1.0036428175308987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1e-05\n",
      "train epoch : 14 , loss : 0.16243767296930528 , nRMSE : 1.0000502643174822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 14 , loss : 0.14738174783332006 , nRMSE : 1.0028474730008785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 15 , loss : 0.1626696693447401 , nRMSE : 1.00006011680907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 15 , loss : 0.146134991305215 , nRMSE : 1.0029219087536008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 16 , loss : 0.16310466227104078 , nRMSE : 1.0001374574633322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 16 , loss : 0.14709941893815995 , nRMSE : 1.0033857337803624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 17 , loss : 0.16382743782311115 , nRMSE : 1.000153338163846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 17 , loss : 0.1469714126416615 , nRMSE : 1.0034665709998156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000002e-06\n",
      "train epoch : 18 , loss : 0.1632137914873519 , nRMSE : 1.0001300638675885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 18 , loss : 0.14598428074802672 , nRMSE : 1.0033470896598324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 19 , loss : 0.16214708905175046 , nRMSE : 1.0000898554383442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 19 , loss : 0.14666352272033692 , nRMSE : 1.0031198687838987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 20 , loss : 0.1626354952465813 , nRMSE : 1.0000964820766398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 20 , loss : 0.14763511908905846 , nRMSE : 1.0031598199678533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 21 , loss : 0.16366290035394002 , nRMSE : 1.0000923392180683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 21 , loss : 0.1472278390611921 , nRMSE : 1.0031352909952977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000002e-07\n",
      "train epoch : 22 , loss : 0.16216256386547717 , nRMSE : 1.0000899772225662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 22 , loss : 0.14770679878337042 , nRMSE : 1.003119927636704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 23 , loss : 0.16277679907825757 , nRMSE : 1.0000885657911405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 23 , loss : 0.14683646431991032 , nRMSE : 1.0031112052317988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:09<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 24 , loss : 0.16230165509963934 , nRMSE : 1.0000890984494204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 24 , loss : 0.14742225557565689 , nRMSE : 1.003115117500862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 25 , loss : 0.16378225459242768 , nRMSE : 1.0000901943058755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 25 , loss : 0.14753509142569132 , nRMSE : 1.0031211159924647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000004e-08\n",
      "train epoch : 26 , loss : 0.16357611294062632 , nRMSE : 1.0000900309331193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 26 , loss : 0.14669120673622404 , nRMSE : 1.0031202216391957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 27 , loss : 0.1625809225833641 , nRMSE : 1.0000899434374002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 27 , loss : 0.14629003490720477 , nRMSE : 1.0031200187310814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 28 , loss : 0.16352955288482163 , nRMSE : 1.0000899536737367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 28 , loss : 0.1477202289870807 , nRMSE : 1.0031200323186193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 29 , loss : 0.1635440134214905 , nRMSE : 1.0000899259587441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 29 , loss : 0.14669835290738514 , nRMSE : 1.0031202575620908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 30 , loss : 0.16365921197915978 , nRMSE : 1.0000898296403018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 30 , loss : 0.14650954497712 , nRMSE : 1.0031195635953858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"before training\")\n",
    "print(f\"train nRMSE : {nrmse_over_data(blmodel , train_dataloader ,device)}\")\n",
    "print(f\"test nRMSE : {nrmse_over_data(blmodel , test_dataloader ,device)}\")\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    blmodel.train()\n",
    "    cumulative_loss = 0\n",
    "    for  batch in tqdm(train_dataloader):\n",
    "        x , y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = blmodel(x)\n",
    "        loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "        cumulative_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    nrmse_train = nrmse_over_data(blmodel , train_dataloader ,device)\n",
    "    if lr!= optimizer.param_groups[0]['lr']:\n",
    "        print(f\"new lr : {optimizer.param_groups[0]['lr']}\")\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    print(f\"train epoch : {epoch +1} , loss : {cumulative_loss/len(train_dataloader)} , nRMSE : {nrmse_train}\")\n",
    "    blmodel.eval()\n",
    "    with torch.inference_mode():\n",
    "        cumulative_loss = 0\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            x , y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = blmodel(x)\n",
    "            loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "            cumulative_loss += loss.item()\n",
    "        nrmse_over_test = nrmse_over_data(blmodel , test_dataloader ,device)\n",
    "        scheduler1.step(nrmse_over_test)\n",
    "        print(f\"test epoch : {epoch +1} , loss : {cumulative_loss/len(test_dataloader)} , nRMSE : {nrmse_over_data(blmodel , test_dataloader,device)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final test on r5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_r5 = r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\final_tests\\final_r5_test\"\n",
    "data = prepare_participants_ccd_data(path_to_r5)\n",
    "\n",
    "data = participants_ccd_data_to_list(data)\n",
    "data = participants_ccd_list_to_trial_rt_pair(data)\n",
    "\n",
    "final_r5_test =pairs_to_fast_loading_shards(data ,\"final_r5_test\" , shard_size)\n",
    "r5_test_data = EEGDataset(final_r5_test ,  shard_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5 test nRMSE : 1.0011487058935713\n"
     ]
    }
   ],
   "source": [
    "r5_test_dataloader = DataLoader(r5_test_data , batch_size=batch_size , shuffle=False )\n",
    "print(f\"r5 test nRMSE : {nrmse_over_data(blmodel , r5_test_dataloader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5 test RMSE : 0.3627938385318386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(blmodel , dataloader , device):\n",
    "    blmodel.eval()\n",
    "    se_sum = 0.0   # sum of squared errors\n",
    "    n = 0          # total number of elements\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for x, y in tqdm(dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = blmodel(x).squeeze(-1)\n",
    "            diff = y_pred - y\n",
    "\n",
    "            se_sum += (diff ** 2).sum().item()\n",
    "            n += y.numel()\n",
    "\n",
    "    rmse = np.sqrt(se_sum / n)\n",
    "    return rmse\n",
    "\n",
    "print(f\"r5 test RMSE : {calculate_rmse(blmodel , r5_test_dataloader,device)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full data preproccessing for encoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_eeg_files_from_dir(dir_path: Path) -> dict[str ,  List[Path] ]:\n",
    "    \"\"\"\n",
    "    from participants directory returns files path orginized in relation to task and run \n",
    "    exemple \n",
    "    dic = {\n",
    "    \"contrastchangeDetection_run-1\" : [path1,path2,path3],\n",
    "    ...   \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dir_path , \"eeg\")\n",
    "    participant_files = {}\n",
    "    for file in os.listdir(dir_path):\n",
    "        if os.path.splitext(file)[1] != \".set\":\n",
    "            continue\n",
    "        elements = file.split(\"_\")\n",
    "        if len(elements ) == 3 :\n",
    "            elements.insert(2 , \"run-1\")\n",
    "        elements[1] += \"_\"+ elements[2]\n",
    "        del elements[2]\n",
    "        participant_files[elements[1]] = Path(os.path.join(dir_path , file))\n",
    "\n",
    "\n",
    "    return participant_files\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_participants_eeg_data(data_dir: Path) -> Dict[str , Dict[str , Tuple[DataFrame , Path]]]:\n",
    "\n",
    "    #dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \n",
    "    results = {}\n",
    "    for release in os.listdir(data_dir):\n",
    "        release_dir_path = os.path.join(data_dir , release)\n",
    "        #go throught the participants directory\n",
    "        for file in os.listdir(release_dir_path):\n",
    "            \n",
    "            if not  file.split(\"-\")[0] == \"sub\" :\n",
    "                continue\n",
    "\n",
    "            participant_id = file\n",
    "            participant_dir_path = os.path.join(release_dir_path , file)\n",
    "\n",
    "            participant_files = load_participant_eeg_files_from_dir(participant_dir_path)\n",
    "            results[participant_dir_path] = [list(participant_files.values())]\n",
    "        \n",
    "\n",
    "    return results\n",
    "\n",
    "def train_val_test_split_by_subject_full_data(data : Dict[str , List[Path]], test_size = 0.1 , val_size = 0.1) -> Tuple[List[Path] , List[Path] , List[Path]]:\n",
    "    subjects = list(data.keys())\n",
    "    train , test = train_test_split(subjects , test_size=test_size + val_size  )\n",
    "    test , val = train_test_split(test , test_size = val_size/(test_size + val_size) )\n",
    "    train_data_paths =[]\n",
    "    for subject in train:\n",
    "        for element in data[subject]:\n",
    "            train_data_paths.extend(element)\n",
    "    test_data_paths = []\n",
    "    for subject in test:\n",
    "        for element in data[subject]:\n",
    "            test_data_paths.extend(element)\n",
    "    val_data_paths = []\n",
    "    for subject in val:\n",
    "        for element in data[subject]:\n",
    "            val_data_paths.extend(element)\n",
    "    return train_data_paths , test_data_paths , val_data_paths  \n",
    "\n",
    "def load_and_shard_eeg_data(data_paths: List[Path], split_type =\"train\" , shard_size = 1000 , window_size = 200 , stride = 20 ,  output_dir = \"full_eeg_data_shards\")-> Tuple[Path  , int] :\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    shard_path = os.path.join(output_dir , split_type)\n",
    "    if not os.path.exists(shard_path):\n",
    "        os.mkdir(shard_path)\n",
    "    else :\n",
    "        size =0\n",
    "        for file in os.listdir( shard_path):\n",
    "            full_path = os.path.join(shard_path , file)\n",
    "            X = np.lib.format.open_memmap(full_path , mode=\"r\" , dtype=np.float32)\n",
    "            size += X.shape[0]\n",
    "            \n",
    "        return shard_path , size\n",
    "    eeg_arrays = []\n",
    "    current_size = 0\n",
    "    index = 0\n",
    "    full_number_of_windows =0\n",
    "    print(f\"proccessing {len(data_paths)} files\")\n",
    "    for i , data_path in tqdm(enumerate(data_paths)):\n",
    "        eeg_data = mne.io.read_raw_eeglab(data_path, preload=True, verbose=False)\n",
    "        eeg_data = eeg_data.get_data()\n",
    "        eeg_data_array = np.array(eeg_data)\n",
    "        eeg_data_array = eeg_data_array[:, : eeg_data_array.shape[1]//window_size*window_size]\n",
    "        eeg_data_array = eeg_data_array.reshape(eeg_data_array.shape[0] , eeg_data_array.shape[1]//window_size , window_size).transpose(1 , 0 , 2)\n",
    "        \n",
    "        eeg_arrays.append(eeg_data_array)\n",
    "        current_size += eeg_data_array.shape[0]\n",
    "        full_number_of_windows += eeg_data_array.shape[0]\n",
    "        if current_size >= shard_size:\n",
    "            new_eeg_data_windows = np.concatenate(eeg_arrays , axis=0)\n",
    "            to_be_added = new_eeg_data_windows[: shard_size]\n",
    "\n",
    "            if current_size == shard_size:\n",
    "                eeg_arrays = []\n",
    "            else :\n",
    "                eeg_arrays = [new_eeg_data_windows[shard_size:]]\n",
    "            \n",
    "            \n",
    "            X = np.lib.format.open_memmap(os.path.join(shard_path , f\"window_shard_{index}.npy\") , mode=\"w+\" , dtype=np.float32 , shape=(to_be_added.shape[0] , to_be_added.shape[1] , to_be_added.shape[2]))\n",
    "            X[:] = to_be_added\n",
    "            X.flush()\n",
    "            current_size = 0\n",
    "            index+=1\n",
    "\n",
    "    new_eeg_data_windows = np.concatenate(eeg_arrays , axis=0)\n",
    "    to_be_added = new_eeg_data_windows[: shard_size]\n",
    "\n",
    "    if current_size == shard_size:\n",
    "        eeg_arrays = []\n",
    "    else :\n",
    "        eeg_arrays = [new_eeg_data_windows[shard_size:]]\n",
    "            \n",
    "            \n",
    "    X = np.lib.format.open_memmap(os.path.join(shard_path , f\"window_shard_{index}.npy\") , mode=\"w+\" , dtype=np.float32 , shape=(to_be_added.shape[0] , to_be_added.shape[1] , to_be_added.shape[2]))\n",
    "    index+=1\n",
    "    X[:] = to_be_added\n",
    "    X.flush()\n",
    "    full_number_of_windows += to_be_added.shape[0]\n",
    "\n",
    "    return shard_path , full_number_of_windows\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\projects\\\\pytorch_training\\\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mprojects\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpytorch_training\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m output_dir = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mD:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mprojects\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mpytorch_training\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfull_eeg_data_shards\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m detailed_data = \u001b[43mprepare_participants_eeg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m train_data_paths , test_data_paths , val_data_paths = train_val_test_split_by_subject_full_data(detailed_data)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mprepare_participants_eeg_data\u001b[39m\u001b[34m(data_dir)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprepare_participants_eeg_data\u001b[39m(data_dir: Path) -> Dict[\u001b[38;5;28mstr\u001b[39m , Dict[\u001b[38;5;28mstr\u001b[39m , Tuple[DataFrame , Path]]]:\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m#dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \u001b[39;00m\n\u001b[32m     32\u001b[39m     results = {}\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m release \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     34\u001b[39m         release_dir_path = os.path.join(data_dir , release)\n\u001b[32m     35\u001b[39m         \u001b[38;5;66;03m#go throught the participants directory\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'D:\\\\projects\\\\pytorch_training\\\\data'"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\projects\\pytorch_training\\data\"\n",
    "output_dir = r\"D:\\projects\\pytorch_training\\full_eeg_data_shards\"\n",
    "detailed_data = prepare_participants_eeg_data(path)\n",
    "train_data_paths , test_data_paths , val_data_paths = train_val_test_split_by_subject_full_data(detailed_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data path  D:\\projects\\pytorch_training\\full_eeg_data_shards\\train with 218000 windows\n",
      "proccessing 212 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [02:58,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proccessing 211 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [03:14,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dir_path  , train_windows_number = load_and_shard_eeg_data(train_data_paths , split_type=\"train\" , shard_size=1000 , window_size=200 , stride=20 , output_dir=output_dir)\n",
    "print(f\"train data path  { train_dir_path} with {train_windows_number} windows\")\n",
    "val_dir_path , val_windows_number = load_and_shard_eeg_data(val_data_paths , split_type=\"val\" , shard_size=1000 , window_size=200 , stride=20 , output_dir=output_dir)\n",
    "test_dir_path , test_windows_number = load_and_shard_eeg_data(test_data_paths , split_type=\"test\" , shard_size=1000 , window_size=200 , stride=20 , output_dir=output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_Dataset(Dataset):\n",
    "    def __init__(self , data_dir ,real_nb_windows , window_size = 200 , stride = 20 , split = \"train\" , shard_size = 1000):\n",
    "        self.data_dir = data_dir\n",
    "        self.real_nb_windows = real_nb_windows\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.split = split\n",
    "        self.shard_size = shard_size\n",
    "        self.number_of_possible_windows_per_shard = ((window_size * shard_size - window_size)//stride)+ 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.real_nb_windows*self.window_size - self.window_size)//self.stride + 1\n",
    "    def __getitem__(self , index):\n",
    "        shard_number = index // self.number_of_possible_windows_per_shard\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import bisect\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from collections import OrderedDict\n",
    "\n",
    "class Encoder_Dataset(Dataset):\n",
    "    def __init__(self, data_dir, window_size=200, stride=20,\n",
    "                 split=\"train\", shard_size=1000, cache_size=2):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.window_size = int(window_size)\n",
    "        self.stride = int(stride)\n",
    "        self.split = split\n",
    "        self.shard_size = int(shard_size)\n",
    "        self.cache_size = cache_size\n",
    "\n",
    "        split_dir = self.data_dir / split\n",
    "        if not split_dir.exists():\n",
    "            raise FileNotFoundError(split_dir)\n",
    "\n",
    "        # discover shards\n",
    "        self.shard_paths = sorted(\n",
    "            (p for p in split_dir.glob(\"window_shard_*.npy\")),\n",
    "            key=lambda p: int(p.stem.split(\"_\")[-1])\n",
    "        )\n",
    "        if not self.shard_paths:\n",
    "            raise RuntimeError(\"No shard files matching window_shard_*.npy\")\n",
    "\n",
    "        # per-shard metadata\n",
    "        self.shard_meta = []\n",
    "        self.prefix_virtual = [0]\n",
    "        total_virtual = 0\n",
    "        for path in self.shard_paths:\n",
    "            arr = np.load(path, mmap_mode=\"r\")\n",
    "            n_base, C, W = arr.shape\n",
    "            if W != self.window_size:\n",
    "                raise ValueError(f\"{path.name}: W={W} != window_size={self.window_size}\")\n",
    "            total_samples = n_base * self.window_size\n",
    "            n_virtual = 0\n",
    "            if total_samples >= self.window_size:\n",
    "                n_virtual = ((total_samples - self.window_size) // self.stride) + 1\n",
    "            self.shard_meta.append({\n",
    "                \"path\": path,\n",
    "                \"n_base\": int(n_base),\n",
    "                \"C\": int(C),\n",
    "                \"W\": int(W),\n",
    "                \"n_virtual\": int(n_virtual),\n",
    "            })\n",
    "            total_virtual += n_virtual\n",
    "            self.prefix_virtual.append(total_virtual)\n",
    "        self.total_virtual = total_virtual\n",
    "        if self.total_virtual == 0:\n",
    "            raise RuntimeError(\"No virtual windows possible.\")\n",
    "\n",
    "        # LRU cache for mmaps (key -> array)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_virtual\n",
    "\n",
    "    def _load_shard(self, shard_idx: int):\n",
    "        path = self.shard_meta[shard_idx][\"path\"]\n",
    "        key = str(path)\n",
    "\n",
    "        # load fresh\n",
    "        mm = np.load(path, mmap_mode=\"r\")\n",
    "\n",
    "        return mm\n",
    "\n",
    "    def _locate(self, global_index: int):\n",
    "        s = bisect.bisect_right(self.prefix_virtual, global_index) - 1\n",
    "        local_idx = global_index - self.prefix_virtual[s]\n",
    "        return s, local_idx\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        if index < 0 or index >= self.total_virtual:\n",
    "            raise IndexError\n",
    "\n",
    "        shard_idx, local_idx = self._locate(index)\n",
    "        meta = self.shard_meta[shard_idx]\n",
    "        shard = self._load_shard(shard_idx)\n",
    "\n",
    "        W = self.window_size\n",
    "        start = local_idx * self.stride\n",
    "        base_idx = start // W\n",
    "        offset = start % W\n",
    "\n",
    "        if offset == 0:\n",
    "            x = shard[base_idx]\n",
    "        else:\n",
    "            first = shard[base_idx, :, offset:]\n",
    "            need = W - first.shape[1]\n",
    "            second = shard[base_idx + 1, :, :need]\n",
    "            x = np.concatenate([first, second], axis=1)\n",
    "\n",
    "        return torch.from_numpy(np.asarray(x, dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\full_eeg_data_shards\"\n",
    "train_dataset = Encoder_Dataset(output_dir , split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for element in tqdm(train_loader):\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
