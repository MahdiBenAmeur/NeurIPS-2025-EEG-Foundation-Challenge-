{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liberaries init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "import torch\n",
    "from torch.utils.data import DataLoader ,  Dataset\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global use\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preproccessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_files_from_dir(dir_path: Path) -> dict[str ,  List[Path] ]:\n",
    "    \"\"\"\n",
    "    from participants directory returns files path orginized in relation to task and run \n",
    "    exemple \n",
    "    dic = {\n",
    "    \"contrastchangeDetection_run-1\" : [path1,path2,path3],\n",
    "    ...   \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dir_path , \"eeg\")\n",
    "    participant_files = {}\n",
    "    for file in os.listdir(dir_path):\n",
    "        elements = file.split(\"_\")\n",
    "        if len(elements ) == 3 :\n",
    "            elements.insert(2 , \"run-1\")\n",
    "        elements[1] += \"_\"+ elements[2]\n",
    "        del elements[2]\n",
    "        if elements[1] not in participant_files:\n",
    "            participant_files[elements[1]] = [Path(os.path.join(dir_path , file))]\n",
    "        else:\n",
    "            participant_files[elements[1]].append(Path(os.path.join(dir_path , file)))\n",
    "    # aka each task has the events , channels , eeg json and eeg raw\n",
    "    for key in participant_files  :\n",
    "        assert len(participant_files[key]) == 4 \n",
    "    return participant_files\n",
    "def prepare_ccd_events(events_fp : Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    from events file returns a dataframe with trial start , trial end , stimulas start , action onset , RT AND SUCCESS\n",
    "\n",
    "    \"\"\"\n",
    "    assert os.path.splitext(events_fp)[1] == \".tsv\"\n",
    "    events = pd.read_csv(events_fp , sep = \"\\t\")\n",
    "    events[\"onset\"] = pd.to_numeric(events[\"onset\"],errors=\"raise\")   \n",
    "    events = events.reset_index(drop=True)\n",
    "    events = events.sort_values(by=\"onset\" , ascending=True)\n",
    "    trials = events[ events[\"value\"] == \"contrastTrial_start\"].copy()\n",
    "    trials[\"trial_start\"] = trials[\"onset\"]\n",
    "\n",
    "    trials[\"trial_end\"] = trials[\"onset\"].shift(-1) \n",
    "    stimulas = events [ events[\"value\"].isin([\"right_target\" ,\"left_target\"])].copy()\n",
    "    action = events [ events[\"value\"].isin([\"right_buttonPress\" ,\"left_buttonPress\"])].copy()\n",
    "    results = []\n",
    "    for i in range(0 ,len(trials)-1 ):\n",
    "        #get the stimulas onset in the trial i duration\n",
    "        stimulas_row = stimulas[ (stimulas[\"onset\"] >= trials[\"trial_start\"].iloc[i]) & (stimulas[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        if stimulas_row.empty:\n",
    "            continue\n",
    "        stimulas_start = float(stimulas_row[\"onset\"].iloc[0])\n",
    "\n",
    "        action_rows = action[ (action[\"onset\"] >= stimulas_start) & (action[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        # if theres no action , theres no rt , theres no success\n",
    "        if action_rows.empty:\n",
    "            \n",
    "            continue\n",
    "        action_row = action_rows.iloc[0]\n",
    "        action_onset = float(action_row[\"onset\"])\n",
    "        rt = action_onset - stimulas_start\n",
    "        success = 1 if action_row[\"feedback\"] == \"smiley_face\" else 0\n",
    "        result ={\n",
    "        \"trial_start\" : float(trials[\"trial_start\"].iloc[i]) ,\n",
    "        \"trial_end\" :float(trials[\"trial_end\"].iloc[i]) ,\n",
    "        \"stimulas_start\" : stimulas_start,\n",
    "        \"action_onset\" :action_onset  ,\n",
    "        \"rt\" : rt ,\n",
    "        \"success\" : success\n",
    "        }\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_participants_ccd_data(data_dir: Path) -> Dict[str , Dict[str , Tuple[DataFrame , Path]]]:\n",
    "\n",
    "    #dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \n",
    "    results = {}\n",
    "    for release in os.listdir(data_dir):\n",
    "        release_dir_path = os.path.join(data_dir , release)\n",
    "        #go throught the participants directory\n",
    "        for file in os.listdir(release_dir_path):\n",
    "            \n",
    "            if not  file.split(\"-\")[0] == \"sub\" :\n",
    "                continue\n",
    "\n",
    "            participant_id = file\n",
    "            participant_dir_path = os.path.join(release_dir_path , file)\n",
    "\n",
    "            results[participant_dir_path] = {}\n",
    "            participant_files = load_participant_files_from_dir(participant_dir_path)\n",
    "            filtered_participant_files = {}\n",
    "            # filter for ccd and sus data\n",
    "            for key in participant_files:\n",
    "                if key.split(\"_\")[0].lower() == \"task-contrastchangedetection\" :\n",
    "                    filtered_participant_files[key] = participant_files[key]\n",
    "            \n",
    "            for task , files in filtered_participant_files.items():\n",
    "                events_path = [path for path in files if \"events\" in str(path)]  \n",
    "                assert len(events_path) == 1\n",
    "                events_path = events_path[0]\n",
    "                eeg_path = [path for path in files if \".set\" in str(path)]\n",
    "\n",
    "                assert len(eeg_path) == 1\n",
    "                df = prepare_ccd_events(events_path)\n",
    "                results[participant_dir_path][task] = (df , eeg_path[0])\n",
    "    return results\n",
    "\n",
    "def participants_ccd_data_to_list(data : dict) -> List[Tuple[DataFrame , Path]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        for task in data[participant]:\n",
    "            results.append(data[participant][task])\n",
    "    return results\n",
    "            \n",
    "def participants_ccd_list_to_trial_rt_pair(data : List[Tuple[DataFrame , Path]]) -> List[Tuple[Path ,Tuple[float,float] , float]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        df , eeg_path = participant\n",
    "        for i in range(0 , len(df)):\n",
    "            results.append((eeg_path , (df[\"stimulas_start\"].iloc[i]+0.5 , df[\"stimulas_start\"].iloc[i]+2.5 ) , df[\"rt\"].iloc[i]))\n",
    "    return results\n",
    "\n",
    "def train_val_test_split_by_subject(data : List[Tuple[Path ,Tuple[float,float] , float]] , test_size : float = 0.1 , val_size : float = 0.1) -> Tuple[List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]]]:\n",
    "    subjects = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject not in subjects:\n",
    "            subjects.append(subject)\n",
    "    train_subjects , test_subjects = train_test_split(subjects , test_size=test_size +val_size)\n",
    "    test_subjects , val_subjects = train_test_split(test_subjects , test_size=val_size/(test_size +val_size))\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    val_data = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject in train_subjects:\n",
    "            train_data.append(element)\n",
    "        elif subject in test_subjects:\n",
    "            test_data.append(element)\n",
    "        elif subject in val_subjects:\n",
    "            val_data.append(element)\n",
    "    return train_data , val_data , test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2727\n"
     ]
    }
   ],
   "source": [
    "data_path= r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\data\"\n",
    "data = prepare_participants_ccd_data(data_path)\n",
    "\n",
    "data = participants_ccd_data_to_list(data)\n",
    "data = participants_ccd_list_to_trial_rt_pair(data)\n",
    "train , val , test = train_val_test_split_by_subject(data)\n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the raw eeg windows data and setting them up for fast import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  preparing the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self , data ):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        eeg_path , (start , end) , rt = self.data[index]\n",
    "        eeg = mne.io.read_raw_eeglab(eeg_path , preload=True)\n",
    "        eeg = eeg.crop(start , end+0.2)\n",
    "        raw = eeg.get_data()\n",
    "        raw = torch.tensor(raw , dtype=torch.float)[:,:200]\n",
    "        rt = torch.tensor(rt , dtype=torch.float)\n",
    "\n",
    "        return raw , rt\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([129, 200])\n",
      "tensor(1.9680)\n"
     ]
    }
   ],
   "source": [
    "data_dir = data_path\n",
    "orig_participants_data= prepare_participants_ccd_data(data_dir)\n",
    "participants_data = participants_ccd_data_to_list(orig_participants_data)\n",
    "trial_rt_pairs = participants_ccd_list_to_trial_rt_pair(participants_data)\n",
    "\n",
    "train_pairs , val_pairs , test_pairs = train_val_test_split_by_subject(trial_rt_pairs)\n",
    "train_data = EEGDataset(train_pairs)\n",
    "test_data = EEGDataset(test_pairs)\n",
    "val_data = EEGDataset(val_pairs)\n",
    "eeg , rt=train_data[0]\n",
    "print(eeg.shape)\n",
    "print(rt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse_over_data(model, dataloader, device):\n",
    "    model.eval()\n",
    "    se_sum = 0.0     # sum of squared errors\n",
    "    sum_y = 0.0      # sum of y\n",
    "    sum_y2 = 0.0     # sum of y^2\n",
    "    n = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x).view_as(y)\n",
    "            diff = y_pred - y\n",
    "\n",
    "            se_sum += diff.pow(2).sum().item()\n",
    "            sum_y  += y.sum().item()\n",
    "            sum_y2 += y.pow(2).sum().item()\n",
    "            n += y.numel()\n",
    "\n",
    "    rmse = (se_sum / n) ** 0.5\n",
    "    var  = (sum_y2 / n) - (sum_y / n) ** 2\n",
    "    std  = var ** 0.5\n",
    "    return rmse / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineCCDmodel(nn.Module):\n",
    "    def __init__(self , nb_channels = 129 , nb_times= 200 , nb_output = 1):\n",
    "        super().__init__()\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nb_channels * nb_times , 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128 , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32 , nb_output)\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        return self.classification_head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "\n",
    "train_dataloader = DataLoader(train_data , batch_size=batch_size , shuffle=True )\n",
    "test_dataloader = DataLoader(test_data , batch_size=batch_size , shuffle=True )\n",
    "val_dataloader = DataLoader(val_data , batch_size=batch_size , shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blmodel = BaselineCCDmodel().to(device)\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(blmodel.parameters() , lr=lr )\n",
    "loss_f = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:45<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 1 , loss : 2.2001759690396927 , nRMSE : 3.5806161986862195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:34<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 1 , loss : 2.501683923933241 , nRMSE : 5.65049749084716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:52<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 2 , loss : 2.055044677327661 , nRMSE : 3.430661161765456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:31<00:00,  3.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 2 , loss : 2.3110683229234485 , nRMSE : 5.430961238418288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:11<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 3 , loss : 1.8290985489592833 , nRMSE : 3.1443548271579513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:36<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 3 , loss : 1.9737843937344022 , nRMSE : 5.019033836051225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:35<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 4 , loss : 1.3947524910464006 , nRMSE : 2.549788013295829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 4 , loss : 1.3538354635238647 , nRMSE : 4.156743029792816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:54<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 5 , loss : 0.7370928981724907 , nRMSE : 1.5661010269722395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:26<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 5 , loss : 0.5410719215869904 , nRMSE : 2.6278338912464565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:40<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 6 , loss : 0.2620777484467801 , nRMSE : 1.0384077306736015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 6 , loss : 0.19712106221252018 , nRMSE : 1.5861234220896496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:41<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 7 , loss : 0.16962885155397303 , nRMSE : 0.9839905639244685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 7 , loss : 0.1620645307832294 , nRMSE : 1.4381842742975406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:40<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 8 , loss : 0.1597794869585949 , nRMSE : 0.9726122504213817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:27<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 8 , loss : 0.15418089512321684 , nRMSE : 1.4027684924432864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:39<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 9 , loss : 0.15766798759646275 , nRMSE : 0.966768034620679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:52<00:00,  5.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 9 , loss : 0.15559112860096824 , nRMSE : 1.4091677069979023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:49<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 10 , loss : 0.15551359370789108 , nRMSE : 0.9629001564508768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:32<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 10 , loss : 0.15656141853994793 , nRMSE : 1.4135556147408703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:13<00:00,  3.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 11 , loss : 0.15447807065485156 , nRMSE : 0.9598304072770033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:26<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 11 , loss : 0.161826491355896 , nRMSE : 1.4371278483672596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:52<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 12 , loss : 0.15464254523463108 , nRMSE : 0.9572870301426318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:35<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 12 , loss : 0.16638468702634177 , nRMSE : 1.4572272174828336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [03:50<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 13 , loss : 0.15222190884763703 , nRMSE : 0.9548371626367876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:30<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 13 , loss : 0.1702550450960795 , nRMSE : 1.4740780074694428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:36<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 14 , loss : 0.15200963868376086 , nRMSE : 0.9527031243265661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:35<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 14 , loss : 0.17335028366910088 , nRMSE : 1.487417076536995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [04:34<00:00,  4.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 15 , loss : 0.152241773026831 , nRMSE : 0.9516386045074963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:26<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 15 , loss : 0.17625372649894822 , nRMSE : 1.4998215745765113\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "blmodel = BaselineCCDmodel().to(device)\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(blmodel.parameters() , lr=lr )\n",
    "loss_f = nn.MSELoss()\n",
    "\n",
    "\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    blmodel.train()\n",
    "    cumulative_loss = 0\n",
    "    for  batch in tqdm(train_dataloader):\n",
    "        x , y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = blmodel(x)\n",
    "        loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "        cumulative_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(f\"train epoch : {epoch +1} , loss : {cumulative_loss/len(train_dataloader)} , nRMSE : {nrmse_over_data(blmodel , train_dataloader ,device)}\")\n",
    "    blmodel.eval()\n",
    "    with torch.inference_mode():\n",
    "        cumulative_loss = 0\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            x , y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = blmodel(x)\n",
    "            loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "            cumulative_loss += loss.item()\n",
    "        print(f\"test epoch : {epoch +1} , loss : {cumulative_loss/len(test_dataloader)} , nRMSE : {nrmse_over_data(blmodel , test_dataloader,device)}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized Baseline model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparing dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
