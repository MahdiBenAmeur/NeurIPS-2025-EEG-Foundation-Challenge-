{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liberaries init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mne\n",
    "import torch\n",
    "from torch.utils.data import DataLoader ,  Dataset\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR ,    MultiStepLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global use\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preproccessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_files_from_dir(dir_path: Path) -> dict[str ,  List[Path] ]:\n",
    "    \"\"\"\n",
    "    from participants directory returns files path orginized in relation to task and run \n",
    "    exemple \n",
    "    dic = {\n",
    "    \"contrastchangeDetection_run-1\" : [path1,path2,path3],\n",
    "    ...   \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dir_path , \"eeg\")\n",
    "    participant_files = {}\n",
    "    for file in os.listdir(dir_path):\n",
    "        elements = file.split(\"_\")\n",
    "        if len(elements ) == 3 :\n",
    "            elements.insert(2 , \"run-1\")\n",
    "        elements[1] += \"_\"+ elements[2]\n",
    "        del elements[2]\n",
    "        if elements[1] not in participant_files:\n",
    "            participant_files[elements[1]] = [Path(os.path.join(dir_path , file))]\n",
    "        else:\n",
    "            participant_files[elements[1]].append(Path(os.path.join(dir_path , file)))\n",
    "    # aka each task has the events , channels , eeg json and eeg raw\n",
    "    for key in participant_files  :\n",
    "        assert len(participant_files[key]) == 4 \n",
    "    return participant_files\n",
    "def prepare_ccd_events(events_fp : Path) -> DataFrame:\n",
    "    \"\"\"\n",
    "    from events file returns a dataframe with trial start , trial end , stimulas start , action onset , RT AND SUCCESS\n",
    "\n",
    "    \"\"\"\n",
    "    assert os.path.splitext(events_fp)[1] == \".tsv\"\n",
    "    events = pd.read_csv(events_fp , sep = \"\\t\")\n",
    "    events[\"onset\"] = pd.to_numeric(events[\"onset\"],errors=\"raise\")   \n",
    "    events = events.reset_index(drop=True)\n",
    "    events = events.sort_values(by=\"onset\" , ascending=True)\n",
    "    trials = events[ events[\"value\"] == \"contrastTrial_start\"].copy()\n",
    "    trials[\"trial_start\"] = trials[\"onset\"]\n",
    "\n",
    "    trials[\"trial_end\"] = trials[\"onset\"].shift(-1) \n",
    "    stimulas = events [ events[\"value\"].isin([\"right_target\" ,\"left_target\"])].copy()\n",
    "    action = events [ events[\"value\"].isin([\"right_buttonPress\" ,\"left_buttonPress\"])].copy()\n",
    "    results = []\n",
    "    for i in range(0 ,len(trials)-1 ):\n",
    "        #get the stimulas onset in the trial i duration\n",
    "        stimulas_row = stimulas[ (stimulas[\"onset\"] >= trials[\"trial_start\"].iloc[i]) & (stimulas[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        if stimulas_row.empty:\n",
    "            continue\n",
    "        stimulas_start = float(stimulas_row[\"onset\"].iloc[0])\n",
    "\n",
    "        action_rows = action[ (action[\"onset\"] >= stimulas_start) & (action[\"onset\"] < trials[\"trial_end\"].iloc[i]) ]\n",
    "        # if theres no action , theres no rt , theres no success\n",
    "        if action_rows.empty:\n",
    "            \n",
    "            continue\n",
    "        action_row = action_rows.iloc[0]\n",
    "        action_onset = float(action_row[\"onset\"])\n",
    "        rt = action_onset - stimulas_start\n",
    "        success = 1 if action_row[\"feedback\"] == \"smiley_face\" else 0\n",
    "        result ={\n",
    "        \"trial_start\" : float(trials[\"trial_start\"].iloc[i]) ,\n",
    "        \"trial_end\" :float(trials[\"trial_end\"].iloc[i]) ,\n",
    "        \"stimulas_start\" : stimulas_start,\n",
    "        \"action_onset\" :action_onset  ,\n",
    "        \"rt\" : rt ,\n",
    "        \"success\" : success\n",
    "        }\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_participants_ccd_data(data_dir: Path) -> Dict[str , Dict[str , Tuple[DataFrame , Path]]]:\n",
    "\n",
    "    #dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \n",
    "    results = {}\n",
    "    for release in os.listdir(data_dir):\n",
    "        release_dir_path = os.path.join(data_dir , release)\n",
    "        #go throught the participants directory\n",
    "        for file in os.listdir(release_dir_path):\n",
    "            \n",
    "            if not  file.split(\"-\")[0] == \"sub\" :\n",
    "                continue\n",
    "\n",
    "            participant_id = file\n",
    "            participant_dir_path = os.path.join(release_dir_path , file)\n",
    "\n",
    "            results[participant_dir_path] = {}\n",
    "            participant_files = load_participant_files_from_dir(participant_dir_path)\n",
    "            filtered_participant_files = {}\n",
    "            # filter for ccd and sus data\n",
    "            for key in participant_files:\n",
    "                if key.split(\"_\")[0].lower() == \"task-contrastchangedetection\" :\n",
    "                    filtered_participant_files[key] = participant_files[key]\n",
    "            \n",
    "            for task , files in filtered_participant_files.items():\n",
    "                events_path = [path for path in files if \"events\" in str(path)]  \n",
    "                assert len(events_path) == 1\n",
    "                events_path = events_path[0]\n",
    "                eeg_path = [path for path in files if \".set\" in str(path)]\n",
    "\n",
    "                assert len(eeg_path) == 1\n",
    "                df = prepare_ccd_events(events_path)\n",
    "                results[participant_dir_path][task] = (df , eeg_path[0])\n",
    "    return results\n",
    "\n",
    "def participants_ccd_data_to_list(data : dict) -> List[Tuple[DataFrame , Path]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        for task in data[participant]:\n",
    "            results.append(data[participant][task])\n",
    "    return results\n",
    "            \n",
    "def participants_ccd_list_to_trial_rt_pair(data : List[Tuple[DataFrame , Path]]) -> List[Tuple[Path ,Tuple[float,float] , float]]:\n",
    "    results = []\n",
    "    for participant in data:\n",
    "        df , eeg_path = participant\n",
    "        for i in range(0 , len(df)):\n",
    "            results.append((eeg_path , (df[\"stimulas_start\"].iloc[i]+0.5 , df[\"stimulas_start\"].iloc[i]+2.5 ) , df[\"rt\"].iloc[i]))\n",
    "    return results\n",
    "\n",
    "def train_val_test_split_by_subject(data : List[Tuple[Path ,Tuple[float,float] , float]] , test_size : float = 0.1 , val_size : float = 0.1) -> Tuple[List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]] , List[Tuple[Path ,Tuple[float,float] , float]]]:\n",
    "    subjects = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject not in subjects:\n",
    "            subjects.append(subject)\n",
    "    train_subjects , test_subjects = train_test_split(subjects , test_size=test_size +val_size)\n",
    "    test_subjects , val_subjects = train_test_split(test_subjects , test_size=val_size/(test_size +val_size))\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    val_data = []\n",
    "    for element in data:\n",
    "        path = element[0]\n",
    "        subject = str(path).split('\\\\')[-3]\n",
    "        if subject in train_subjects:\n",
    "            train_data.append(element)\n",
    "        elif subject in test_subjects:\n",
    "            test_data.append(element)\n",
    "        elif subject in val_subjects:\n",
    "            val_data.append(element)\n",
    "    return train_data , val_data , test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500\n"
     ]
    }
   ],
   "source": [
    "data_path= r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\data\"\n",
    "data = prepare_participants_ccd_data(data_path)\n",
    "\n",
    "data = participants_ccd_data_to_list(data)\n",
    "data = participants_ccd_list_to_trial_rt_pair(data)\n",
    "train , val , test = train_val_test_split_by_subject(data)\n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extracting the raw eeg windows data and setting them up for fast import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairs_to_fast_loading_shards(data : List[Tuple[Path ,Tuple[float,float] , float]] , split = \"train\" , shard_size : int = 1000):\n",
    "    shards_path = \"shards_dir\"\n",
    "    split_path = os.path.join(shards_path , split)\n",
    "\n",
    "    if not os.path.exists(shards_path):\n",
    "        os.makedirs(shards_path)\n",
    "\n",
    "    if not os.path.exists(split_path):\n",
    "        os.makedirs(split_path)\n",
    "    else:\n",
    "        return split_path\n",
    "\n",
    "\n",
    "    shard_index=0\n",
    "    window_shard_path = os.path.join(split_path , f\"window_shard_{shard_index}.npy\")\n",
    "    rt_shard_path = os.path.join(split_path , f\"rt_shard_{shard_index}.npy\")\n",
    "    windows =[]\n",
    "    rts =[]\n",
    "    for index , element in tqdm(enumerate(data)):\n",
    "        if index!=0 and index % shard_size == 0:\n",
    "            window_array = np.array(windows)\n",
    "            rt_array = np.array(rts)\n",
    "            X = np.lib.format.open_memmap(window_shard_path , dtype='float32' , mode='w+' , shape=(window_array.shape[0] , window_array.shape[1] , window_array.shape[2]))\n",
    "            X[:] = window_array\n",
    "            del X\n",
    "            Y = np.lib.format.open_memmap(rt_shard_path , dtype='float32' , mode='w+' , shape=(rt_array.shape[0] ,))\n",
    "            Y[:] = rt_array\n",
    "            del Y\n",
    "            shard_index+=1\n",
    "            window_shard_path = os.path.join(split_path , f\"window_shard_{shard_index}.npy\")\n",
    "            rt_shard_path = os.path.join(split_path , f\"rt_shard_{shard_index}.npy\")\n",
    "            windows =[]\n",
    "            rts =[]\n",
    "        eeg_path , (start , end) , rt = element\n",
    "        eeg = mne.io.read_raw_eeglab(eeg_path , preload=True)\n",
    "        eeg = eeg.crop(start , end+0.2)\n",
    "        raw = eeg.get_data()[: ,:200]\n",
    "        windows.append(raw)\n",
    "        rts.append(rt)\n",
    "    window_array = np.array(windows)\n",
    "    rt_array = np.array(rts)\n",
    "    if len(window_array) > 0:\n",
    "        X = np.lib.format.open_memmap(window_shard_path , dtype='float32' , mode='w+' , shape=(window_array.shape[0] , window_array.shape[1] , window_array.shape[2]))\n",
    "        X[:] = window_array\n",
    "        del X\n",
    "        Y = np.lib.format.open_memmap(rt_shard_path , dtype='float32' , mode='w+' , shape=(rt_array.shape[0] ,))\n",
    "        Y[:] = rt_array\n",
    "        del Y\n",
    "    return split_path\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8478it [15:57,  8.85it/s]\n",
      "1108it [01:52,  9.86it/s]\n",
      "914it [01:31, 10.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shards_dir\\\\val'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_size = 1000\n",
    "pairs_to_fast_loading_shards(train , \"train\" ,shard_size)\n",
    "pairs_to_fast_loading_shards(test , \"test\",shard_size)\n",
    "pairs_to_fast_loading_shards(val , \"val\",shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self , shards_path , shard_size  =1000):\n",
    "        self.shards_path = shards_path\n",
    "        self.numbers_of_shards = int( len(os.listdir(self.shards_path)) / 2)\n",
    "        self.shard_size = shard_size\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        length = 0\n",
    "        for shard_path in os.listdir(self.shards_path):\n",
    "            if \"window\" in shard_path:\n",
    "                window_shard_path = os.path.join(self.shards_path , shard_path)\n",
    "                shard = np.lib.format.open_memmap(window_shard_path , mode=\"r\")\n",
    "                size = shard.shape[0]\n",
    "                length += size\n",
    "        return length\n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        shard_pos = index // self.shard_size \n",
    "        window_shard_path = os.path.join(self.shards_path , f\"window_shard_{shard_pos}.npy\")\n",
    "        X = np.lib.format.open_memmap(window_shard_path , mode=\"r\")\n",
    "        rt_shard_path = os.path.join(self.shards_path , f\"rt_shard_{shard_pos}.npy\")\n",
    "        Y = np.lib.format.open_memmap(rt_shard_path , mode=\"r\")\n",
    "        raw = X[index % self.shard_size]\n",
    "        rt = Y[index % self.shard_size]\n",
    "        return raw , rt\n",
    "    \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 200)\n",
      "1.768\n"
     ]
    }
   ],
   "source": [
    "train_pairs_shards_path = pairs_to_fast_loading_shards(train , \"train\" , shard_size)\n",
    "test_pairs_shards_path = pairs_to_fast_loading_shards(test , \"test\" ,  shard_size)\n",
    "val_pairs_shards_path =pairs_to_fast_loading_shards(val , \"val\" , shard_size)\n",
    "train_data = EEGDataset(train_pairs_shards_path ,  shard_size)\n",
    "test_data = EEGDataset(test_pairs_shards_path , shard_size)\n",
    "val_data = EEGDataset(val_pairs_shards_path ,shard_size)\n",
    "eeg , rt=train_data[0]\n",
    "print(eeg.shape)\n",
    "print(rt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse_over_data(model, dataloader, device):\n",
    "    model.eval()\n",
    "    se_sum = 0.0     # sum of squared errors\n",
    "    sum_y = 0.0      # sum of y\n",
    "    sum_y2 = 0.0     # sum of y^2\n",
    "    n = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "\n",
    "            y_pred = model(x).view_as(y)\n",
    "            diff = y_pred - y\n",
    "\n",
    "            se_sum += diff.pow(2).sum().item()\n",
    "            sum_y  += y.sum().item()\n",
    "            sum_y2 += y.pow(2).sum().item()\n",
    "            n += y.numel()\n",
    "\n",
    "    rmse = (se_sum / n) ** 0.5\n",
    "    var  = (sum_y2 / n) - (sum_y / n) ** 2\n",
    "    std  = var ** 0.5\n",
    "    return rmse / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Importance_extraction(nn.Module):\n",
    "    def __init__(self , nb_channels = 129 , nb_times= 200 ):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear( nb_times , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 1)   \n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self , x):\n",
    "        x = self.classifier(x)\n",
    "        return self.softmax(x)  \n",
    "      \n",
    "    \n",
    "class Section_attention(nn.Module):\n",
    "    def __init__(self , nb_channels=129 , nb_times=10):\n",
    "        super().__init__()\n",
    "        self.nb_channels = nb_channels\n",
    "        self.nb_times = nb_times\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self , Q , K , V):\n",
    "        attn = self.softmax((Q @ K.transpose(-1 , -2)) / (self.nb_times ** 0.5))\n",
    "        res = attn @ V\n",
    "        return res\n",
    "\n",
    "\n",
    "class Multi_section_attention(nn.Module):\n",
    "    def __init__(self , nb_channels=129 , nb_times=200 , nb_output=1 , section_size=10):\n",
    "        super().__init__()\n",
    "        self.importance  = Importance_extraction(nb_channels , nb_times)\n",
    "        self.section_attention = Section_attention(nb_channels , section_size)\n",
    "\n",
    "        self.section_size = section_size\n",
    "        self.nb_of_sections = nb_times // section_size\n",
    "        self.ll = nn.Linear(nb_times , nb_times)\n",
    "        self.nb_times = nb_times\n",
    "        self.nb_channels = nb_channels\n",
    "\n",
    "        self.to_q = nn.Linear(nb_times , nb_times)\n",
    "        self.to_k = nn.Linear(nb_times , nb_times)\n",
    "        self.to_v = nn.Linear(nb_times , nb_times)\n",
    "\n",
    "    def forward(self , x):\n",
    "        imp = self.importance(x)\n",
    "        adjusted_x = x * imp\n",
    "\n",
    "        Q = self.to_q(adjusted_x)\n",
    "        K = self.to_k(adjusted_x)\n",
    "        V = self.to_v(adjusted_x)\n",
    "\n",
    "        Q = Q.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        \n",
    "        K = K.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        V =V.reshape(\n",
    "            adjusted_x.shape[0] , adjusted_x.shape[1] , self.nb_of_sections , self.section_size\n",
    "        ).transpose(1 , 2)  # (b, sections, c, section_size)\n",
    "        \n",
    "\n",
    "        x = self.section_attention(Q , K , V)\n",
    "        x = x.transpose(1 , 2).reshape(x.shape[0] , self.nb_channels , self.nb_times)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self ,  nb_times ):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(nb_times,) ,  requires_grad=True)\n",
    "        self.beta = nn.Parameter(torch.zeros(nb_times,) ,  requires_grad=True)\n",
    "    def forward(self , original  , attention_res):\n",
    "        add = original + attention_res\n",
    "        mean = add.mean(dim=-1,keepdim=True)\n",
    "        stand_div = add.std(dim=-1 , keepdim=True) + 1e-4 # just in case el std ta7 lel 0\n",
    "        result = (add - mean)/stand_div\n",
    "        return self.gamma * result + self.beta\n",
    "\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self , nb_channels = 129 , nb_times= 200 , nb_output = 1 , section_size = 20):\n",
    "        super().__init__()\n",
    "        self.multi_section_attention = Multi_section_attention(nb_channels , nb_times , nb_output , section_size)\n",
    "        self.add_norm = LayerNorm(nb_times)\n",
    "        self.classifer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(nb_times * nb_channels , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256 , 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64 , 1),\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        attention_res = self.multi_section_attention(x)\n",
    "        x= self.add_norm(x , attention_res)\n",
    "        x = self.classifer(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chat enhanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section_attention(nn.Module):\n",
    "    def __init__(self, nb_channels=129, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.nb_channels = nb_channels\n",
    "        self.section_size = section_size\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "        self.scale = d_k ** 0.5\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.out = nn.Linear(heads * d_k, section_size)  # bring back to section_size\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Q,K,V: (b, sections, c, heads, d_k)\n",
    "        # move heads before c for matmul\n",
    "        Q = Q.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "        K = K.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "        V = V.permute(0,1,3,2,4)  # (b, sections, heads, c, d_k)\n",
    "\n",
    "        attn = self.softmax((Q @ K.transpose(-1, -2)) / self.scale)   # (b, sections, heads, c, c)\n",
    "        x = attn @ V                                                  # (b, sections, heads, c, d_k)\n",
    "\n",
    "        # merge heads back into feature dim per channel, then project to section_size\n",
    "        x = x.permute(0,1,3,2,4).contiguous()                         # (b, sections, c, heads, d_k)\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2], -1)            # (b, sections, c, heads*d_k)\n",
    "        x = self.out(x)                                               # (b, sections, c, section_size)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Multi_section_attention(nn.Module):\n",
    "    def __init__(self, nb_channels=129, nb_times=200, nb_output=1, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.importance  = Importance_extraction(nb_channels, nb_times)\n",
    "        self.section_size = section_size\n",
    "        self.nb_of_sections = nb_times // section_size\n",
    "        self.nb_times = nb_times\n",
    "        self.nb_channels = nb_channels\n",
    "        self.heads = heads\n",
    "        self.d_k = d_k\n",
    "\n",
    "        # QKV AFTER sectioning: project last dim (section_size) → heads*d_k\n",
    "        self.to_q = nn.Linear(section_size, heads * d_k)\n",
    "        self.to_k = nn.Linear(section_size, heads * d_k)\n",
    "        self.to_v = nn.Linear(section_size, heads * d_k)\n",
    "\n",
    "        self.section_attention = Section_attention(nb_channels, section_size, heads, d_k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        imp = self.importance(x)                       # (b, c, 1) softmax over channels\n",
    "        adjusted_x = x * imp                           # (b, c, t)\n",
    "\n",
    "        # split into sections\n",
    "        z = adjusted_x.reshape(adjusted_x.shape[0], adjusted_x.shape[1],\n",
    "                               self.nb_of_sections, self.section_size) \\\n",
    "                        .transpose(1, 2)               # (b, sections, c, section_size)\n",
    "\n",
    "        # per-section projections\n",
    "        Q = self.to_q(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)  # (b, sections, c, h, d_k)\n",
    "        K = self.to_k(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)\n",
    "        V = self.to_v(z).view(z.shape[0], z.shape[1], z.shape[2], self.heads, self.d_k)\n",
    "\n",
    "        x = self.section_attention(Q, K, V)            # (b, sections, c, section_size)\n",
    "        x = x.transpose(1, 2).reshape(x.shape[0], self.nb_channels, self.nb_times)  # (b, c, t)\n",
    "        return x\n",
    "\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self, nb_channels=129, nb_times=200, nb_output=1, section_size=10, heads=4, d_k=8):\n",
    "        super().__init__()\n",
    "        self.multi_section_attention = Multi_section_attention(\n",
    "            nb_channels, nb_times, nb_output, section_size, heads, d_k\n",
    "        )\n",
    "        self.add_norm = LayerNorm(nb_times)\n",
    "\n",
    "        self.classifer = nn.Sequential(\n",
    "            # pool over time → (b, c)\n",
    "            nn.Identity(),  # keep style\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc1 = nn.Linear(nb_channels, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        att = self.multi_section_attention(x)      # (b, c, t)\n",
    "        x = self.add_norm(x, att)                  # (b, c, t)\n",
    "\n",
    "        x = x.mean(dim=-1)                         # (b, c)   <- key change\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_data , batch_size=batch_size , shuffle=True )\n",
    "test_dataloader = DataLoader(test_data , batch_size=batch_size , shuffle=True )\n",
    "val_dataloader = DataLoader(val_data , batch_size=batch_size , shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/265 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# testing model is working\n",
    "test_model = BaseLineModel().to(device)\n",
    "\n",
    "for  batch in tqdm(train_dataloader):\n",
    "    x , y = batch\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = test_model(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blmodel = BaseLineModel().to(device)\n",
    "\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(blmodel.parameters() , lr=lr  )\n",
    "scheduler1 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer , patience=3 )\n",
    "\n",
    "loss_f = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training\n",
      "train nRMSE : 4.480052098182609\n",
      "test nRMSE : 4.717848996036528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:10<00:00, 24.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 1 , loss : 0.40520924464711605 , nRMSE : 1.0025569050593914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 1 , loss : 0.14846871665545872 , nRMSE : 1.0097055700236715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 2 , loss : 0.17553673976997158 , nRMSE : 1.0023003397262085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 30.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 2 , loss : 0.14967387872082846 , nRMSE : 1.0091809934723883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:09<00:00, 29.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 3 , loss : 0.17405283382197595 , nRMSE : 1.0097702271613769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 3 , loss : 0.14659395068883896 , nRMSE : 1.003266740865236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:11<00:00, 24.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 4 , loss : 0.17243017315302256 , nRMSE : 1.0010080762708315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 29.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 4 , loss : 0.14578632499490465 , nRMSE : 1.0001818349502491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 5 , loss : 0.17080556124729931 , nRMSE : 1.0143750752413943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 5 , loss : 0.15546711151088988 , nRMSE : 1.0289269138474666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 6 , loss : 0.16832041999079148 , nRMSE : 1.0251970796885526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 6 , loss : 0.1580700327243124 , nRMSE : 1.0441054706743322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 7 , loss : 0.1673442859132335 , nRMSE : 1.006906228604693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 7 , loss : 0.1506179194365229 , nRMSE : 1.0174576745936144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 30.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 8 , loss : 0.1672310360197751 , nRMSE : 1.0003092584008333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 8 , loss : 0.14689572325774602 , nRMSE : 1.0041322525051222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 0.0001\n",
      "train epoch : 9 , loss : 0.16327298660323306 , nRMSE : 1.0019474276963944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 9 , loss : 0.14592890058244978 , nRMSE : 1.0000027288596784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 10 , loss : 0.16364460593124605 , nRMSE : 1.0005962765715646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 10 , loss : 0.14559138544968198 , nRMSE : 1.0004283691311116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 11 , loss : 0.1637277679763875 , nRMSE : 1.0017963732660657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 11 , loss : 0.14632193722895215 , nRMSE : 1.0000064304217653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 12 , loss : 0.1631973660076564 , nRMSE : 1.0058162830110964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 12 , loss : 0.14644078229154858 , nRMSE : 1.0011210587203478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 13 , loss : 0.16454196268657467 , nRMSE : 1.0001906442227615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 13 , loss : 0.1467181546347482 , nRMSE : 1.0036428175308987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1e-05\n",
      "train epoch : 14 , loss : 0.16243767296930528 , nRMSE : 1.0000502643174822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 14 , loss : 0.14738174783332006 , nRMSE : 1.0028474730008785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 15 , loss : 0.1626696693447401 , nRMSE : 1.00006011680907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 15 , loss : 0.146134991305215 , nRMSE : 1.0029219087536008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 16 , loss : 0.16310466227104078 , nRMSE : 1.0001374574633322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 16 , loss : 0.14709941893815995 , nRMSE : 1.0033857337803624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 17 , loss : 0.16382743782311115 , nRMSE : 1.000153338163846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 17 , loss : 0.1469714126416615 , nRMSE : 1.0034665709998156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000002e-06\n",
      "train epoch : 18 , loss : 0.1632137914873519 , nRMSE : 1.0001300638675885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 18 , loss : 0.14598428074802672 , nRMSE : 1.0033470896598324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 19 , loss : 0.16214708905175046 , nRMSE : 1.0000898554383442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 19 , loss : 0.14666352272033692 , nRMSE : 1.0031198687838987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 30.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 20 , loss : 0.1626354952465813 , nRMSE : 1.0000964820766398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 20 , loss : 0.14763511908905846 , nRMSE : 1.0031598199678533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 21 , loss : 0.16366290035394002 , nRMSE : 1.0000923392180683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 21 , loss : 0.1472278390611921 , nRMSE : 1.0031352909952977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000002e-07\n",
      "train epoch : 22 , loss : 0.16216256386547717 , nRMSE : 1.0000899772225662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 22 , loss : 0.14770679878337042 , nRMSE : 1.003119927636704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 23 , loss : 0.16277679907825757 , nRMSE : 1.0000885657911405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 23 , loss : 0.14683646431991032 , nRMSE : 1.0031112052317988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:09<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 24 , loss : 0.16230165509963934 , nRMSE : 1.0000890984494204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 24 , loss : 0.14742225557565689 , nRMSE : 1.003115117500862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 25 , loss : 0.16378225459242768 , nRMSE : 1.0000901943058755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 35.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 25 , loss : 0.14753509142569132 , nRMSE : 1.0031211159924647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new lr : 1.0000000000000004e-08\n",
      "train epoch : 26 , loss : 0.16357611294062632 , nRMSE : 1.0000900309331193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 33.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 26 , loss : 0.14669120673622404 , nRMSE : 1.0031202216391957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 27 , loss : 0.1625809225833641 , nRMSE : 1.0000899434374002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 27 , loss : 0.14629003490720477 , nRMSE : 1.0031200187310814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 28 , loss : 0.16352955288482163 , nRMSE : 1.0000899536737367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:00<00:00, 36.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 28 , loss : 0.1477202289870807 , nRMSE : 1.0031200323186193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 29 , loss : 0.1635440134214905 , nRMSE : 1.0000899259587441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 29 , loss : 0.14669835290738514 , nRMSE : 1.0031202575620908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265/265 [00:08<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch : 30 , loss : 0.16365921197915978 , nRMSE : 1.0000898296403018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 34.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test epoch : 30 , loss : 0.14650954497712 , nRMSE : 1.0031195635953858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"before training\")\n",
    "print(f\"train nRMSE : {nrmse_over_data(blmodel , train_dataloader ,device)}\")\n",
    "print(f\"test nRMSE : {nrmse_over_data(blmodel , test_dataloader ,device)}\")\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    blmodel.train()\n",
    "    cumulative_loss = 0\n",
    "    for  batch in tqdm(train_dataloader):\n",
    "        x , y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_pred = blmodel(x)\n",
    "        loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "        cumulative_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    nrmse_train = nrmse_over_data(blmodel , train_dataloader ,device)\n",
    "    if lr!= optimizer.param_groups[0]['lr']:\n",
    "        print(f\"new lr : {optimizer.param_groups[0]['lr']}\")\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    print(f\"train epoch : {epoch +1} , loss : {cumulative_loss/len(train_dataloader)} , nRMSE : {nrmse_train}\")\n",
    "    blmodel.eval()\n",
    "    with torch.inference_mode():\n",
    "        cumulative_loss = 0\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            x , y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = blmodel(x)\n",
    "            loss = loss_f(y_pred.squeeze(-1) , y)\n",
    "            cumulative_loss += loss.item()\n",
    "        nrmse_over_test = nrmse_over_data(blmodel , test_dataloader ,device)\n",
    "        scheduler1.step(nrmse_over_test)\n",
    "        print(f\"test epoch : {epoch +1} , loss : {cumulative_loss/len(test_dataloader)} , nRMSE : {nrmse_over_data(blmodel , test_dataloader,device)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final test on r5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_r5 = r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\final_tests\\final_r5_test\"\n",
    "data = prepare_participants_ccd_data(path_to_r5)\n",
    "\n",
    "data = participants_ccd_data_to_list(data)\n",
    "data = participants_ccd_list_to_trial_rt_pair(data)\n",
    "\n",
    "final_r5_test =pairs_to_fast_loading_shards(data ,\"final_r5_test\" , shard_size)\n",
    "r5_test_data = EEGDataset(final_r5_test ,  shard_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5 test nRMSE : 1.0011487058935713\n"
     ]
    }
   ],
   "source": [
    "r5_test_dataloader = DataLoader(r5_test_data , batch_size=batch_size , shuffle=False )\n",
    "print(f\"r5 test nRMSE : {nrmse_over_data(blmodel , r5_test_dataloader,device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:01<00:00, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r5 test RMSE : 0.3627938385318386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(blmodel , dataloader , device):\n",
    "    blmodel.eval()\n",
    "    se_sum = 0.0   # sum of squared errors\n",
    "    n = 0          # total number of elements\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for x, y in tqdm(dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = blmodel(x).squeeze(-1)\n",
    "            diff = y_pred - y\n",
    "\n",
    "            se_sum += (diff ** 2).sum().item()\n",
    "            n += y.numel()\n",
    "\n",
    "    rmse = np.sqrt(se_sum / n)\n",
    "    return rmse\n",
    "\n",
    "print(f\"r5 test RMSE : {calculate_rmse(blmodel , r5_test_dataloader,device)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full data preproccessing for encoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_participant_eeg_files_from_dir(dir_path: Path) -> dict[str ,  List[Path] ]:\n",
    "    \"\"\"\n",
    "    from participants directory returns files path orginized in relation to task and run \n",
    "    exemple \n",
    "    dic = {\n",
    "    \"contrastchangeDetection_run-1\" : [path1,path2,path3],\n",
    "    ...   \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    dir_path = os.path.join(dir_path , \"eeg\")\n",
    "    participant_files = {}\n",
    "    for file in os.listdir(dir_path):\n",
    "        if os.path.splitext(file)[1] != \".set\":\n",
    "            continue\n",
    "        elements = file.split(\"_\")\n",
    "        if len(elements ) == 3 :\n",
    "            elements.insert(2 , \"run-1\")\n",
    "        elements[1] += \"_\"+ elements[2]\n",
    "        del elements[2]\n",
    "        participant_files[elements[1]] = Path(os.path.join(dir_path , file))\n",
    "\n",
    "\n",
    "    return participant_files\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def prepare_participants_eeg_data(data_dir: Path) -> Dict[str , Dict[str , Tuple[DataFrame , Path]]]:\n",
    "\n",
    "    #dictionary that will have for each  participant (path as key) a dictionary with the ccd-run (key) and values as the df , and path to raw eeg file \n",
    "    results = {}\n",
    "    for release in os.listdir(data_dir):\n",
    "        release_dir_path = os.path.join(data_dir , release)\n",
    "        #go throught the participants directory\n",
    "        for file in os.listdir(release_dir_path):\n",
    "            \n",
    "            if not  file.split(\"-\")[0] == \"sub\" :\n",
    "                continue\n",
    "\n",
    "            participant_id = file\n",
    "            participant_dir_path = os.path.join(release_dir_path , file)\n",
    "\n",
    "            participant_files = load_participant_eeg_files_from_dir(participant_dir_path)\n",
    "            results[participant_dir_path] = [list(participant_files.values())]\n",
    "        \n",
    "\n",
    "    return results\n",
    "\n",
    "def train_val_test_split_by_subject_full_data(data : Dict[str , List[Path]], test_size = 0.1 , val_size = 0.1) -> Tuple[List[Path] , List[Path] , List[Path]]:\n",
    "    subjects = list(data.keys())\n",
    "    train , test = train_test_split(subjects , test_size=test_size + val_size  )\n",
    "    test , val = train_test_split(test , test_size = val_size/(test_size + val_size) )\n",
    "    train_data_paths =[]\n",
    "    for subject in train:\n",
    "        for element in data[subject]:\n",
    "            train_data_paths.extend(element)\n",
    "    test_data_paths = []\n",
    "    for subject in test:\n",
    "        for element in data[subject]:\n",
    "            test_data_paths.extend(element)\n",
    "    val_data_paths = []\n",
    "    for subject in val:\n",
    "        for element in data[subject]:\n",
    "            val_data_paths.extend(element)\n",
    "    return train_data_paths , test_data_paths , val_data_paths  \n",
    "\n",
    "def load_and_shard_eeg_data(data_paths: List[Path], split_type =\"train\" , shard_size = 1000 , window_size = 200 , stride = 20)-> Tuple[Path  , int] :\n",
    "    dir=\"full_eeg_data_shards\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "    shard_path = os.path.join(dir , split_type)\n",
    "    if not os.path.exists(shard_path):\n",
    "        os.mkdir(shard_path)\n",
    "    else :\n",
    "        size =0\n",
    "        for file in os.listdir( shard_path):\n",
    "            full_path = os.path.join(shard_path , file)\n",
    "            X = np.lib.format.open_memmap(full_path , mode=\"r\" , dtype=np.float32)\n",
    "            size += X.shape[0]\n",
    "        return shard_path , size\n",
    "    eeg_arrays = []\n",
    "    current_size = 0\n",
    "    index = 0\n",
    "    full_number_of_windows =0\n",
    "    for i , data_path in tqdm(enumerate(data_paths)):\n",
    "        eeg_data = mne.io.read_raw_eeglab(data_path, preload=True, verbose=False)\n",
    "        eeg_data = eeg_data.get_data()\n",
    "        eeg_data_array = np.array(eeg_data)\n",
    "        eeg_data_array = eeg_data_array[:, : eeg_data_array.shape[1]//window_size*window_size]\n",
    "        eeg_data_array = eeg_data_array.reshape(eeg_data_array.shape[0] , eeg_data_array.shape[1]//window_size , window_size).transpose(1 , 0 , 2)\n",
    "        \n",
    "        eeg_arrays.append(eeg_data_array)\n",
    "        current_size += eeg_data_array.shape[0]\n",
    "        full_number_of_windows += eeg_data_array.shape[0]\n",
    "        if current_size >= shard_size:\n",
    "            new_eeg_data_windows = np.concatenate(eeg_arrays , axis=0)\n",
    "            to_be_added = new_eeg_data_windows[: shard_size]\n",
    "\n",
    "            if current_size == shard_size:\n",
    "                eeg_arrays = []\n",
    "            else :\n",
    "                eeg_arrays = [new_eeg_data_windows[shard_size:]]\n",
    "            \n",
    "            \n",
    "            X = np.lib.format.open_memmap(os.path.join(shard_path , f\"window_shard_{index}.npy\") , mode=\"w+\" , dtype=np.float32 , shape=(to_be_added.shape[0] , to_be_added.shape[1] , to_be_added.shape[2]))\n",
    "            X[:] = to_be_added\n",
    "            X.flush()\n",
    "\n",
    "            index+=1\n",
    "\n",
    "    new_eeg_data_windows = np.concatenate(eeg_arrays , axis=0)\n",
    "    to_be_added = new_eeg_data_windows[: shard_size]\n",
    "\n",
    "    if current_size == shard_size:\n",
    "        eeg_arrays = []\n",
    "    else :\n",
    "        eeg_arrays = [new_eeg_data_windows[shard_size:]]\n",
    "            \n",
    "            \n",
    "    X = np.lib.format.open_memmap(os.path.join(shard_path , f\"window_shard_{index}.npy\") , mode=\"w+\" , dtype=np.float32 , shape=(to_be_added.shape[0] , to_be_added.shape[1] , to_be_added.shape[2]))\n",
    "    index+=1\n",
    "    X[:] = to_be_added\n",
    "    X.flush()\n",
    "\n",
    "    return shard_path , full_number_of_windows\n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\disque d\\ai_stuff\\projects\\pytorchtraining\\eeg_competition\\data\"\n",
    "detailed_data = prepare_participants_eeg_data(path)\n",
    "train_data_paths , test_data_paths , val_data_paths = train_val_test_split_by_subject_full_data(detailed_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "206it [00:33,  6.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\io\\eeglab\\_eeglab.py:76\u001b[39m, in \u001b[36m_readmat\u001b[39m\u001b[34m(fname, uint16_codec)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     read_mat = \u001b[43m_import_pymatreader_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEEGLAB I/O\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# pymatreader not installed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\utils\\check.py:202\u001b[39m, in \u001b[36m_import_pymatreader_funcs\u001b[39m\u001b[34m(purpose)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_import_pymatreader_funcs\u001b[39m(purpose):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     pymatreader = \u001b[43m_soft_import\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpymatreader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpurpose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pymatreader.read_mat\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\utils\\check.py:429\u001b[39m, in \u001b[36m_soft_import\u001b[39m\u001b[34m(name, purpose, strict, min_version)\u001b[39m\n\u001b[32m    428\u001b[39m         extra += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (found version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgot_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    430\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpurpose\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to work, the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextra\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is needed, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut it could not be imported. Use the following installation method \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mappropriate for your environment:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    433\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    434\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    conda install -c conda-forge \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m     )\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m mod\n",
      "\u001b[31mRuntimeError\u001b[39m: For EEGLAB I/O to work, the module pymatreader is needed, but it could not be imported. Use the following installation method appropriate for your environment:\n\n    pip install pymatreader\n    conda install -c conda-forge pymatreader",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[227]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mload_and_shard_eeg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_paths\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[225]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mload_and_shard_eeg_data\u001b[39m\u001b[34m(data_paths, split_type, shard_size, window_size, stride)\u001b[39m\n\u001b[32m     85\u001b[39m full_number_of_windows =\u001b[32m0\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i , data_path \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(data_paths)):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     eeg_data = \u001b[43mmne\u001b[49m\u001b[43m.\u001b[49m\u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_raw_eeglab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     eeg_data = eeg_data.get_data()\n\u001b[32m     89\u001b[39m     eeg_data_array = np.array(eeg_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:328\u001b[39m, in \u001b[36mread_raw_eeglab\u001b[39m\u001b[34m(input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;129m@fill_doc\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_raw_eeglab\u001b[39m(\n\u001b[32m    286\u001b[39m     input_fname,\n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m     verbose=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    292\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mRawEEGLAB\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    293\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Read an EEGLAB .set file.\u001b[39;00m\n\u001b[32m    294\u001b[39m \n\u001b[32m    295\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m \u001b[33;03m    .. versionadded:: 0.11.0\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRawEEGLAB\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_fname\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_fname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43meog\u001b[49m\u001b[43m=\u001b[49m\u001b[43meog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmontage_units\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmontage_units\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-269>:10\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:450\u001b[39m, in \u001b[36mRawEEGLAB.__init__\u001b[39m\u001b[34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[39m\n\u001b[32m    438\u001b[39m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    440\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m     verbose=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    448\u001b[39m ):\n\u001b[32m    449\u001b[39m     input_fname = \u001b[38;5;28mstr\u001b[39m(_check_fname(input_fname, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33minput_fname\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     eeg = \u001b[43m_check_load_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eeg.trials != \u001b[32m1\u001b[39m:\n\u001b[32m    452\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    453\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe number of trials is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meeg.trials\u001b[38;5;132;01m:\u001b[39;00m\u001b[33md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. It must be 1 for raw\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    454\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m files. Please use `mne.io.read_epochs_eeglab` if\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    455\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m the .set file contains epochs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    456\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\io\\eeglab\\eeglab.py:74\u001b[39m, in \u001b[36m_check_load_mat\u001b[39m\u001b[34m(fname, uint16_codec)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check if the mat struct contains 'EEG'.\"\"\"\u001b[39;00m\n\u001b[32m     73\u001b[39m fname = _check_fname(fname, \u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m eeg = \u001b[43m_readmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mALLEEG\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m eeg:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLoading an ALLEEG array is not supported. Please contact\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmne-python developers for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     79\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\mne\\io\\eeglab\\_eeglab.py:78\u001b[39m, in \u001b[36m_readmat\u001b[39m\u001b[34m(fname, uint16_codec)\u001b[39m\n\u001b[32m     76\u001b[39m     read_mat = _import_pymatreader_funcs(\u001b[33m\"\u001b[39m\u001b[33mEEGLAB I/O\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:  \u001b[38;5;66;03m# pymatreader not installed\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     eeg = \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muint16_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[43muint16_codec\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _check_for_scipy_mat_struct(eeg)\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:235\u001b[39m, in \u001b[36mloadmat\u001b[39m\u001b[34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    234\u001b[39m     MR, _ = mat_reader_factory(f, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     matfile_dict = \u001b[43mMR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spmatrix:\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse, coo_matrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:333\u001b[39m, in \u001b[36mMatFile5Reader.get_variables\u001b[39m\u001b[34m(self, variable_names)\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    335\u001b[39m     warnings.warn(\n\u001b[32m    336\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnreadable variable \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, because \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    337\u001b[39m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\scipy\\io\\matlab\\_mio5.py:291\u001b[39m, in \u001b[36mMatFile5Reader.read_var_array\u001b[39m\u001b[34m(self, header, process)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    275\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m''' Read array, given `header`\u001b[39;00m\n\u001b[32m    276\u001b[39m \n\u001b[32m    277\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    289\u001b[39m \u001b[33;03m       `process`.\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_matrix_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_mio5_utils.pyx:665\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_mio5_utils.pyx:734\u001b[39m, in \u001b[36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_mio_utils.pyx:11\u001b[39m, in \u001b[36mscipy.io.matlab._mio_utils.squeeze_element\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_mio_utils.pyx:18\u001b[39m, in \u001b[36mscipy.io.matlab._mio_utils.squeeze_element\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\disque d\\ai_stuff\\projects\\pytorchtraining\\pytorch_training\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:1617\u001b[39m, in \u001b[36m_squeeze_dispatcher\u001b[39m\u001b[34m(a, axis)\u001b[39m\n\u001b[32m   1612\u001b[39m     a = concatenate((a,) * repeats)[:new_size]\n\u001b[32m   1614\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[32m-> \u001b[39m\u001b[32m1617\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_squeeze_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1618\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[32m   1621\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[32m   1622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msqueeze\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "load_and_shard_eeg_data(train_data_paths , split_type=\"train\" , shard_size=1000 , window_size=200 , stride=20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
